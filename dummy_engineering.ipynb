{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c5652b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jupyter Notebook 02 — Dummy Scoring Engine + UI Snapshots\n",
    "# ---------------------------------------------------------\n",
    "# Objetivo:\n",
    "# 1) Cargar los CSV del Notebook 01 (factories.csv y top10_skus.csv)\n",
    "# 2) Recalcular métricas derivadas (days_of_supply, stockout_date_est, stock_needed_next_7d)\n",
    "# 3) Generar risk_oos_7d con reglas dummy (explicables)\n",
    "# 4) Seleccionar Top 10 SKUs por fábrica (aunque ya vengan, aquí se recalcula)\n",
    "# 5) Recalcular factory overall risk (max SKU risk) + critical SKU\n",
    "# 6) Exportar snapshots listos para GitHub Pages:\n",
    "#    - public/data/factories.json\n",
    "#    - public/data/predictions_latest.json\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09caea0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('data/processed/factories.csv'),\n",
       " PosixPath('data/processed/top10_skus.csv'))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === CONFIG ===\n",
    "PROCESSED_DIR = Path(\"data/processed\")\n",
    "FACTORIES_CSV = PROCESSED_DIR / \"factories.csv\"\n",
    "TOP10_CSV = PROCESSED_DIR / \"top10_skus.csv\"\n",
    "\n",
    "PUBLIC_DIR = Path(\"public/data\")  # para GitHub Pages con Vite/React suele ser /public/data\n",
    "PUBLIC_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "AS_OF_DATE = \"2026-01-14\"  # usa la del JSON/CSV; si quieres la inferimos automáticamente abajo\n",
    "HORIZON_DAYS = 7\n",
    "TOP_K = 10\n",
    "\n",
    "assert FACTORIES_CSV.exists(), f\"No encuentro {FACTORIES_CSV.resolve()}\"\n",
    "assert TOP10_CSV.exists(), f\"No encuentro {TOP10_CSV.resolve()}\"\n",
    "\n",
    "FACTORIES_CSV, TOP10_CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bbb4ced3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2026-01-14 00:00:00')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === LOAD ===\n",
    "df_fact = pd.read_csv(FACTORIES_CSV)\n",
    "df = pd.read_csv(TOP10_CSV)\n",
    "\n",
    "# inferir as_of_date si viene en el csv\n",
    "if \"as_of_date\" in df.columns and df[\"as_of_date\"].notna().any():\n",
    "    AS_OF_DATE = str(df[\"as_of_date\"].dropna().iloc[0])\n",
    "\n",
    "as_of = pd.to_datetime(AS_OF_DATE)\n",
    "as_of\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "312272d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HELPERS: reglas dummy coherentes ===\n",
    "\n",
    "def clamp01(x):\n",
    "    return float(max(0.0, min(1.0, x)))\n",
    "\n",
    "def compute_days_of_supply(on_hand, in_transit, on_order, daily_demand):\n",
    "    inv = (on_hand or 0) + (in_transit or 0) + (on_order or 0)\n",
    "    dd = daily_demand if daily_demand and daily_demand > 0 else np.nan\n",
    "    return inv / dd\n",
    "\n",
    "def compute_stockout_date(as_of_dt, days_of_supply):\n",
    "    if pd.isna(days_of_supply):\n",
    "        return None\n",
    "    # redondeo hacia abajo para fecha conservadora\n",
    "    d = int(np.floor(days_of_supply))\n",
    "    return (as_of_dt + pd.Timedelta(days=d)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def compute_stock_needed_next_7d(on_hand, in_transit, on_order, daily_demand, safety_factor=1.10):\n",
    "    inv = (on_hand or 0) + (in_transit or 0) + (on_order or 0)\n",
    "    dd = daily_demand if daily_demand and daily_demand > 0 else 0\n",
    "    demand_7d = dd * HORIZON_DAYS\n",
    "    need = max(0.0, demand_7d * safety_factor - inv)\n",
    "    return float(np.round(need))\n",
    "\n",
    "def risk_from_days_of_supply(dos):\n",
    "    # base risk en función de cobertura (coherente con lo que hablamos)\n",
    "    if pd.isna(dos):\n",
    "        return 0.5\n",
    "    if dos < 4:\n",
    "        return 0.85\n",
    "    if dos < 7:\n",
    "        return 0.60\n",
    "    if dos < 10:\n",
    "        return 0.28\n",
    "    return 0.10\n",
    "\n",
    "def compute_risk_oos_7d(dos, promo_uplift, lead_time_std, scrap_rate, missingness_ratio=None):\n",
    "    risk = risk_from_days_of_supply(dos)\n",
    "\n",
    "    # ajustes simples, explicables\n",
    "    if promo_uplift is not None and promo_uplift > 1.10:\n",
    "        risk += 0.10\n",
    "    if lead_time_std is not None and lead_time_std > 1.5:\n",
    "        risk += 0.10\n",
    "    if scrap_rate is not None and scrap_rate > 0.02:\n",
    "        risk += 0.05\n",
    "    if missingness_ratio is not None and missingness_ratio > 0.03:\n",
    "        risk += 0.05\n",
    "\n",
    "    return clamp01(risk)\n",
    "\n",
    "def compute_confidence(missingness_ratio=None, drift_score=None):\n",
    "    # si no tienes missingness/drift, regresa un valor alto por default\n",
    "    conf = 0.90\n",
    "    if missingness_ratio is not None and not pd.isna(missingness_ratio):\n",
    "        conf -= min(0.25, float(missingness_ratio) * 3.0)  # 0.05 -> -0.15 aprox\n",
    "    if drift_score is not None and not pd.isna(drift_score):\n",
    "        conf -= min(0.20, float(drift_score) * 1.5)        # 0.10 -> -0.15 aprox\n",
    "    return clamp01(conf)\n",
    "\n",
    "def build_drivers_row(dos, promo_uplift, lead_time_std, scrap_rate, missingness_ratio=None):\n",
    "    # Genera 3 drivers máximos, con \"impactos\" dummy pero consistentes\n",
    "    drivers = []\n",
    "\n",
    "    # dos bajo => sube riesgo\n",
    "    if not pd.isna(dos):\n",
    "        drivers.append((\"days_of_supply\", float(np.round(max(0.0, (7 - dos) / 10), 3))))\n",
    "\n",
    "    if promo_uplift is not None and not pd.isna(promo_uplift):\n",
    "        drivers.append((\"promo_uplift_index\", float(np.round(max(0.0, promo_uplift - 1.0), 3))))\n",
    "\n",
    "    if lead_time_std is not None and not pd.isna(lead_time_std):\n",
    "        drivers.append((\"lead_time_days_std\", float(np.round(max(0.0, (lead_time_std - 1.0) / 5), 3))))\n",
    "\n",
    "    if scrap_rate is not None and not pd.isna(scrap_rate):\n",
    "        drivers.append((\"scrap_rate_7d\", float(np.round(max(0.0, (scrap_rate - 0.01)), 3))))\n",
    "\n",
    "    if missingness_ratio is not None and not pd.isna(missingness_ratio):\n",
    "        drivers.append((\"missingness_ratio_24h\", float(np.round(missingness_ratio, 3))))\n",
    "\n",
    "    # ordenar por impacto desc y quedarnos con top3\n",
    "    drivers = sorted(drivers, key=lambda x: x[1], reverse=True)[:3]\n",
    "    return [{\"feature\": f, \"impact\": imp} for f, imp in drivers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36ca5bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_version</th>\n",
       "      <th>as_of_date</th>\n",
       "      <th>factory_id</th>\n",
       "      <th>factory_name</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>factory_overall_risk_oos_7d</th>\n",
       "      <th>rank_in_factory</th>\n",
       "      <th>...</th>\n",
       "      <th>scrap_rate_7d</th>\n",
       "      <th>driver1_feature</th>\n",
       "      <th>driver1_impact</th>\n",
       "      <th>driver2_feature</th>\n",
       "      <th>driver2_impact</th>\n",
       "      <th>driver3_feature</th>\n",
       "      <th>driver3_impact</th>\n",
       "      <th>drivers_json</th>\n",
       "      <th>missingness_ratio_24h</th>\n",
       "      <th>drift_score_7d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mx_pilot_sku_v1</td>\n",
       "      <td>2026-01-14</td>\n",
       "      <td>MX_TOL_01</td>\n",
       "      <td>Planta Toluca</td>\n",
       "      <td>Estado de México</td>\n",
       "      <td>Toluca</td>\n",
       "      <td>19.2826</td>\n",
       "      <td>-99.6557</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006</td>\n",
       "      <td>days_of_supply</td>\n",
       "      <td>0.32</td>\n",
       "      <td>lead_time_days_std</td>\n",
       "      <td>0.22</td>\n",
       "      <td>promo_uplift_index</td>\n",
       "      <td>0.12</td>\n",
       "      <td>[{\"feature\": \"days_of_supply\", \"impact\": 0.32}...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mx_pilot_sku_v1</td>\n",
       "      <td>2026-01-14</td>\n",
       "      <td>MX_TOL_01</td>\n",
       "      <td>Planta Toluca</td>\n",
       "      <td>Estado de México</td>\n",
       "      <td>Toluca</td>\n",
       "      <td>19.2826</td>\n",
       "      <td>-99.6557</td>\n",
       "      <td>0.82</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019</td>\n",
       "      <td>days_of_supply</td>\n",
       "      <td>0.21</td>\n",
       "      <td>promo_uplift_index</td>\n",
       "      <td>0.18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"feature\": \"promo_uplift_index\", \"impact\": 0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mx_pilot_sku_v1</td>\n",
       "      <td>2026-01-14</td>\n",
       "      <td>MX_IRA_02</td>\n",
       "      <td>Planta Irapuato</td>\n",
       "      <td>Guanajuato</td>\n",
       "      <td>Irapuato</td>\n",
       "      <td>20.6767</td>\n",
       "      <td>-101.3563</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017</td>\n",
       "      <td>days_of_supply</td>\n",
       "      <td>0.16</td>\n",
       "      <td>promo_uplift_index</td>\n",
       "      <td>0.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{\"feature\": \"days_of_supply\", \"impact\": 0.16}...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_version  as_of_date factory_id     factory_name             state  \\\n",
       "0  mx_pilot_sku_v1  2026-01-14  MX_TOL_01    Planta Toluca  Estado de México   \n",
       "1  mx_pilot_sku_v1  2026-01-14  MX_TOL_01    Planta Toluca  Estado de México   \n",
       "2  mx_pilot_sku_v1  2026-01-14  MX_IRA_02  Planta Irapuato        Guanajuato   \n",
       "\n",
       "       city      lat       lon  factory_overall_risk_oos_7d  rank_in_factory  \\\n",
       "0    Toluca  19.2826  -99.6557                         0.82                1   \n",
       "1    Toluca  19.2826  -99.6557                         0.82                2   \n",
       "2  Irapuato  20.6767 -101.3563                         0.46                1   \n",
       "\n",
       "   ... scrap_rate_7d driver1_feature driver1_impact     driver2_feature  \\\n",
       "0  ...         0.006  days_of_supply           0.32  lead_time_days_std   \n",
       "1  ...         0.019  days_of_supply           0.21  promo_uplift_index   \n",
       "2  ...         0.017  days_of_supply           0.16  promo_uplift_index   \n",
       "\n",
       "   driver2_impact     driver3_feature driver3_impact  \\\n",
       "0            0.22  promo_uplift_index           0.12   \n",
       "1            0.18                 NaN            NaN   \n",
       "2            0.10                 NaN            NaN   \n",
       "\n",
       "                                        drivers_json  missingness_ratio_24h  \\\n",
       "0  [{\"feature\": \"days_of_supply\", \"impact\": 0.32}...                    NaN   \n",
       "1  [{\"feature\": \"promo_uplift_index\", \"impact\": 0...                    NaN   \n",
       "2  [{\"feature\": \"days_of_supply\", \"impact\": 0.16}...                    NaN   \n",
       "\n",
       "   drift_score_7d  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "\n",
       "[3 rows x 35 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === NORMALIZAR COLUMNAS (por si tu CSV no trae algunas) ===\n",
    "# En tu top10_skus.csv del notebook 1, quizá no incluiste missingness/drift.\n",
    "# Si no existen, las ponemos como NaN para que el código funcione igual.\n",
    "\n",
    "for col in [\"missingness_ratio_24h\", \"drift_score_7d\"]:\n",
    "    if col not in df.columns:\n",
    "        df[col] = np.nan\n",
    "\n",
    "# Asegurar numéricos\n",
    "num_cols = [\n",
    "    \"on_hand_units\",\"in_transit_units\",\"on_order_units\",\"daily_demand_units\",\n",
    "    \"lead_time_days_mean\",\"lead_time_days_std\",\"promo_uplift_index\",\"scrap_rate_7d\",\n",
    "    \"missingness_ratio_24h\",\"drift_score_7d\"\n",
    "]\n",
    "for c in num_cols:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7edbdab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factory_id</th>\n",
       "      <th>sku_id</th>\n",
       "      <th>sku_name</th>\n",
       "      <th>days_of_supply_calc</th>\n",
       "      <th>stockout_date_est_calc</th>\n",
       "      <th>stock_needed_next_7d_calc</th>\n",
       "      <th>risk_oos_7d_calc</th>\n",
       "      <th>confidence_calc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MX_TOL_01</td>\n",
       "      <td>TOL-INF-004</td>\n",
       "      <td>Infant Formula Stage 1 800g</td>\n",
       "      <td>3.393939</td>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>71050.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MX_TOL_01</td>\n",
       "      <td>TOL-DAI-002</td>\n",
       "      <td>Milk Whole 1L</td>\n",
       "      <td>4.076923</td>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>94200.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MX_IRA_02</td>\n",
       "      <td>IRA-DAI-006</td>\n",
       "      <td>Yogurt Strawberry 1L</td>\n",
       "      <td>6.193548</td>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>23350.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MX_VDM_03</td>\n",
       "      <td>VDM-WAT-003</td>\n",
       "      <td>Water 600ml 24-pack</td>\n",
       "      <td>4.043478</td>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>84100.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  factory_id       sku_id                     sku_name  days_of_supply_calc  \\\n",
       "0  MX_TOL_01  TOL-INF-004  Infant Formula Stage 1 800g             3.393939   \n",
       "1  MX_TOL_01  TOL-DAI-002                Milk Whole 1L             4.076923   \n",
       "2  MX_IRA_02  IRA-DAI-006         Yogurt Strawberry 1L             6.193548   \n",
       "3  MX_VDM_03  VDM-WAT-003          Water 600ml 24-pack             4.043478   \n",
       "\n",
       "  stockout_date_est_calc  stock_needed_next_7d_calc  risk_oos_7d_calc  \\\n",
       "0             2026-01-17                    71050.0              0.95   \n",
       "1             2026-01-18                    94200.0              0.70   \n",
       "2             2026-01-20                    23350.0              0.60   \n",
       "3             2026-01-18                    84100.0              0.60   \n",
       "\n",
       "   confidence_calc  \n",
       "0              0.9  \n",
       "1              0.9  \n",
       "2              0.9  \n",
       "3              0.9  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === RECALC DERIVED FIELDS + RISK + CONFIDENCE + DRIVERS ===\n",
    "\n",
    "df2 = df.copy()\n",
    "\n",
    "df2[\"days_of_supply_calc\"] = df2.apply(\n",
    "    lambda r: compute_days_of_supply(r[\"on_hand_units\"], r[\"in_transit_units\"], r[\"on_order_units\"], r[\"daily_demand_units\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df2[\"stockout_date_est_calc\"] = df2[\"days_of_supply_calc\"].apply(lambda dos: compute_stockout_date(as_of, dos))\n",
    "\n",
    "df2[\"stock_needed_next_7d_calc\"] = df2.apply(\n",
    "    lambda r: compute_stock_needed_next_7d(r[\"on_hand_units\"], r[\"in_transit_units\"], r[\"on_order_units\"], r[\"daily_demand_units\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df2[\"risk_oos_7d_calc\"] = df2.apply(\n",
    "    lambda r: compute_risk_oos_7d(\n",
    "        r[\"days_of_supply_calc\"],\n",
    "        r[\"promo_uplift_index\"],\n",
    "        r[\"lead_time_days_std\"],\n",
    "        r[\"scrap_rate_7d\"],\n",
    "        r[\"missingness_ratio_24h\"]\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df2[\"confidence_calc\"] = df2.apply(\n",
    "    lambda r: compute_confidence(r[\"missingness_ratio_24h\"], r[\"drift_score_7d\"]),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df2[\"drivers_calc_json\"] = df2.apply(\n",
    "    lambda r: json.dumps(\n",
    "        build_drivers_row(\n",
    "            r[\"days_of_supply_calc\"],\n",
    "            r[\"promo_uplift_index\"],\n",
    "            r[\"lead_time_days_std\"],\n",
    "            r[\"scrap_rate_7d\"],\n",
    "            r[\"missingness_ratio_24h\"]\n",
    "        ),\n",
    "        ensure_ascii=False\n",
    "    ),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df2[[\n",
    "    \"factory_id\",\"sku_id\",\"sku_name\",\n",
    "    \"days_of_supply_calc\",\"stockout_date_est_calc\",\"stock_needed_next_7d_calc\",\n",
    "    \"risk_oos_7d_calc\",\"confidence_calc\"\n",
    "]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d6d1c8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_version</th>\n",
       "      <th>as_of_date</th>\n",
       "      <th>factory_id</th>\n",
       "      <th>factory_name</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>factory_overall_risk_oos_7d</th>\n",
       "      <th>rank_in_factory</th>\n",
       "      <th>...</th>\n",
       "      <th>drivers_json</th>\n",
       "      <th>missingness_ratio_24h</th>\n",
       "      <th>drift_score_7d</th>\n",
       "      <th>days_of_supply_calc</th>\n",
       "      <th>stockout_date_est_calc</th>\n",
       "      <th>stock_needed_next_7d_calc</th>\n",
       "      <th>risk_oos_7d_calc</th>\n",
       "      <th>confidence_calc</th>\n",
       "      <th>drivers_calc_json</th>\n",
       "      <th>rank_in_factory_calc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mx_pilot_sku_v1</td>\n",
       "      <td>2026-01-14</td>\n",
       "      <td>MX_IRA_02</td>\n",
       "      <td>Planta Irapuato</td>\n",
       "      <td>Guanajuato</td>\n",
       "      <td>Irapuato</td>\n",
       "      <td>20.6767</td>\n",
       "      <td>-101.3563</td>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[{\"feature\": \"days_of_supply\", \"impact\": 0.16}...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.193548</td>\n",
       "      <td>2026-01-20</td>\n",
       "      <td>23350.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[{\"feature\": \"days_of_supply\", \"impact\": 0.081...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mx_pilot_sku_v1</td>\n",
       "      <td>2026-01-14</td>\n",
       "      <td>MX_TOL_01</td>\n",
       "      <td>Planta Toluca</td>\n",
       "      <td>Estado de México</td>\n",
       "      <td>Toluca</td>\n",
       "      <td>19.2826</td>\n",
       "      <td>-99.6557</td>\n",
       "      <td>0.82</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[{\"feature\": \"days_of_supply\", \"impact\": 0.32}...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.393939</td>\n",
       "      <td>2026-01-17</td>\n",
       "      <td>71050.0</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[{\"feature\": \"days_of_supply\", \"impact\": 0.361...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mx_pilot_sku_v1</td>\n",
       "      <td>2026-01-14</td>\n",
       "      <td>MX_TOL_01</td>\n",
       "      <td>Planta Toluca</td>\n",
       "      <td>Estado de México</td>\n",
       "      <td>Toluca</td>\n",
       "      <td>19.2826</td>\n",
       "      <td>-99.6557</td>\n",
       "      <td>0.82</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>[{\"feature\": \"promo_uplift_index\", \"impact\": 0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.076923</td>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>94200.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[{\"feature\": \"days_of_supply\", \"impact\": 0.292...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mx_pilot_sku_v1</td>\n",
       "      <td>2026-01-14</td>\n",
       "      <td>MX_VDM_03</td>\n",
       "      <td>Planta Valle de México</td>\n",
       "      <td>Estado de México</td>\n",
       "      <td>Cuautitlán Izcalli</td>\n",
       "      <td>19.6469</td>\n",
       "      <td>-99.2460</td>\n",
       "      <td>0.68</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>[{\"feature\": \"days_of_supply\", \"impact\": 0.24}...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.043478</td>\n",
       "      <td>2026-01-18</td>\n",
       "      <td>84100.0</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[{\"feature\": \"days_of_supply\", \"impact\": 0.296...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset_version  as_of_date factory_id            factory_name  \\\n",
       "2  mx_pilot_sku_v1  2026-01-14  MX_IRA_02         Planta Irapuato   \n",
       "0  mx_pilot_sku_v1  2026-01-14  MX_TOL_01           Planta Toluca   \n",
       "1  mx_pilot_sku_v1  2026-01-14  MX_TOL_01           Planta Toluca   \n",
       "3  mx_pilot_sku_v1  2026-01-14  MX_VDM_03  Planta Valle de México   \n",
       "\n",
       "              state                city      lat       lon  \\\n",
       "2        Guanajuato            Irapuato  20.6767 -101.3563   \n",
       "0  Estado de México              Toluca  19.2826  -99.6557   \n",
       "1  Estado de México              Toluca  19.2826  -99.6557   \n",
       "3  Estado de México  Cuautitlán Izcalli  19.6469  -99.2460   \n",
       "\n",
       "   factory_overall_risk_oos_7d  rank_in_factory  ...  \\\n",
       "2                         0.46                1  ...   \n",
       "0                         0.82                1  ...   \n",
       "1                         0.82                2  ...   \n",
       "3                         0.68                1  ...   \n",
       "\n",
       "                                        drivers_json missingness_ratio_24h  \\\n",
       "2  [{\"feature\": \"days_of_supply\", \"impact\": 0.16}...                   NaN   \n",
       "0  [{\"feature\": \"days_of_supply\", \"impact\": 0.32}...                   NaN   \n",
       "1  [{\"feature\": \"promo_uplift_index\", \"impact\": 0...                   NaN   \n",
       "3  [{\"feature\": \"days_of_supply\", \"impact\": 0.24}...                   NaN   \n",
       "\n",
       "  drift_score_7d  days_of_supply_calc  stockout_date_est_calc  \\\n",
       "2            NaN             6.193548              2026-01-20   \n",
       "0            NaN             3.393939              2026-01-17   \n",
       "1            NaN             4.076923              2026-01-18   \n",
       "3            NaN             4.043478              2026-01-18   \n",
       "\n",
       "   stock_needed_next_7d_calc risk_oos_7d_calc  confidence_calc  \\\n",
       "2                    23350.0             0.60              0.9   \n",
       "0                    71050.0             0.95              0.9   \n",
       "1                    94200.0             0.70              0.9   \n",
       "3                    84100.0             0.60              0.9   \n",
       "\n",
       "                                   drivers_calc_json  rank_in_factory_calc  \n",
       "2  [{\"feature\": \"days_of_supply\", \"impact\": 0.081...                     1  \n",
       "0  [{\"feature\": \"days_of_supply\", \"impact\": 0.361...                     1  \n",
       "1  [{\"feature\": \"days_of_supply\", \"impact\": 0.292...                     2  \n",
       "3  [{\"feature\": \"days_of_supply\", \"impact\": 0.296...                     1  \n",
       "\n",
       "[4 rows x 42 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === RE-TOP10 POR FÁBRICA (basado en risk_oos_7d_calc) ===\n",
    "df_topk = (\n",
    "    df2.sort_values([\"factory_id\", \"risk_oos_7d_calc\"], ascending=[True, False])\n",
    "       .groupby(\"factory_id\", as_index=False, group_keys=False)\n",
    "       .head(TOP_K)\n",
    "       .copy()\n",
    ")\n",
    "\n",
    "# rank\n",
    "df_topk[\"rank_in_factory_calc\"] = (\n",
    "    df_topk.groupby(\"factory_id\").cumcount() + 1\n",
    ")\n",
    "\n",
    "df_topk.sort_values([\"factory_id\", \"rank_in_factory_calc\"]).head(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "813788fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factory_id</th>\n",
       "      <th>factory_name</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>critical_sku_id</th>\n",
       "      <th>critical_sku_name</th>\n",
       "      <th>overall_risk_oos_7d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MX_TOL_01</td>\n",
       "      <td>Planta Toluca</td>\n",
       "      <td>Estado de México</td>\n",
       "      <td>Toluca</td>\n",
       "      <td>19.2826</td>\n",
       "      <td>-99.6557</td>\n",
       "      <td>TOL-INF-004</td>\n",
       "      <td>Infant Formula Stage 1 800g</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MX_IRA_02</td>\n",
       "      <td>Planta Irapuato</td>\n",
       "      <td>Guanajuato</td>\n",
       "      <td>Irapuato</td>\n",
       "      <td>20.6767</td>\n",
       "      <td>-101.3563</td>\n",
       "      <td>IRA-DAI-006</td>\n",
       "      <td>Yogurt Strawberry 1L</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MX_VDM_03</td>\n",
       "      <td>Planta Valle de México</td>\n",
       "      <td>Estado de México</td>\n",
       "      <td>Cuautitlán Izcalli</td>\n",
       "      <td>19.6469</td>\n",
       "      <td>-99.2460</td>\n",
       "      <td>VDM-WAT-003</td>\n",
       "      <td>Water 600ml 24-pack</td>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  factory_id            factory_name             state                city  \\\n",
       "0  MX_TOL_01           Planta Toluca  Estado de México              Toluca   \n",
       "1  MX_IRA_02         Planta Irapuato        Guanajuato            Irapuato   \n",
       "2  MX_VDM_03  Planta Valle de México  Estado de México  Cuautitlán Izcalli   \n",
       "\n",
       "       lat       lon critical_sku_id            critical_sku_name  \\\n",
       "0  19.2826  -99.6557     TOL-INF-004  Infant Formula Stage 1 800g   \n",
       "1  20.6767 -101.3563     IRA-DAI-006         Yogurt Strawberry 1L   \n",
       "2  19.6469  -99.2460     VDM-WAT-003          Water 600ml 24-pack   \n",
       "\n",
       "   overall_risk_oos_7d  \n",
       "0                 0.95  \n",
       "1                 0.60  \n",
       "2                 0.60  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === FACTORY SUMMARY RECALC (overall risk = max SKU risk) + critical SKU ===\n",
    "df_factory_summary = (\n",
    "    df_topk.sort_values([\"factory_id\", \"risk_oos_7d_calc\"], ascending=[True, False])\n",
    "           .groupby(\"factory_id\", as_index=False)\n",
    "           .first()[[\"factory_id\",\"sku_id\",\"sku_name\",\"risk_oos_7d_calc\"]]\n",
    "           .rename(columns={\n",
    "               \"sku_id\":\"critical_sku_id\",\n",
    "               \"sku_name\":\"critical_sku_name\",\n",
    "               \"risk_oos_7d_calc\":\"overall_risk_oos_7d\"\n",
    "           })\n",
    ")\n",
    "\n",
    "# unir con df_fact (mantener lat/lon, nombre, etc.)\n",
    "keep_cols = [\"factory_id\",\"factory_name\",\"state\",\"city\",\"lat\",\"lon\"]\n",
    "df_fact_min = df_fact[keep_cols].drop_duplicates(\"factory_id\")\n",
    "\n",
    "df_fact2 = df_fact_min.merge(df_factory_summary, on=\"factory_id\", how=\"left\")\n",
    "\n",
    "df_fact2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "488ef2bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>factory_id</th>\n",
       "      <th>factory_name</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>critical_sku_id</th>\n",
       "      <th>critical_sku_name</th>\n",
       "      <th>overall_risk_oos_7d</th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MX_TOL_01</td>\n",
       "      <td>Planta Toluca</td>\n",
       "      <td>Estado de México</td>\n",
       "      <td>Toluca</td>\n",
       "      <td>19.2826</td>\n",
       "      <td>-99.6557</td>\n",
       "      <td>TOL-INF-004</td>\n",
       "      <td>Infant Formula Stage 1 800g</td>\n",
       "      <td>0.95</td>\n",
       "      <td>RED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MX_IRA_02</td>\n",
       "      <td>Planta Irapuato</td>\n",
       "      <td>Guanajuato</td>\n",
       "      <td>Irapuato</td>\n",
       "      <td>20.6767</td>\n",
       "      <td>-101.3563</td>\n",
       "      <td>IRA-DAI-006</td>\n",
       "      <td>Yogurt Strawberry 1L</td>\n",
       "      <td>0.60</td>\n",
       "      <td>YELLOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MX_VDM_03</td>\n",
       "      <td>Planta Valle de México</td>\n",
       "      <td>Estado de México</td>\n",
       "      <td>Cuautitlán Izcalli</td>\n",
       "      <td>19.6469</td>\n",
       "      <td>-99.2460</td>\n",
       "      <td>VDM-WAT-003</td>\n",
       "      <td>Water 600ml 24-pack</td>\n",
       "      <td>0.60</td>\n",
       "      <td>YELLOW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  factory_id            factory_name             state                city  \\\n",
       "0  MX_TOL_01           Planta Toluca  Estado de México              Toluca   \n",
       "1  MX_IRA_02         Planta Irapuato        Guanajuato            Irapuato   \n",
       "2  MX_VDM_03  Planta Valle de México  Estado de México  Cuautitlán Izcalli   \n",
       "\n",
       "       lat       lon critical_sku_id            critical_sku_name  \\\n",
       "0  19.2826  -99.6557     TOL-INF-004  Infant Formula Stage 1 800g   \n",
       "1  20.6767 -101.3563     IRA-DAI-006         Yogurt Strawberry 1L   \n",
       "2  19.6469  -99.2460     VDM-WAT-003          Water 600ml 24-pack   \n",
       "\n",
       "   overall_risk_oos_7d severity  \n",
       "0                 0.95      RED  \n",
       "1                 0.60   YELLOW  \n",
       "2                 0.60   YELLOW  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === SEVERITY LABEL (útil para UI) ===\n",
    "def severity_label(risk, red=0.7, yellow=0.35):\n",
    "    if pd.isna(risk):\n",
    "        return \"UNKNOWN\"\n",
    "    if risk >= red:\n",
    "        return \"RED\"\n",
    "    if risk >= yellow:\n",
    "        return \"YELLOW\"\n",
    "    return \"GREEN\"\n",
    "\n",
    "df_fact2[\"severity\"] = df_fact2[\"overall_risk_oos_7d\"].apply(severity_label)\n",
    "df_fact2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54e361ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bl/wz4tv3rs7vsd1fmkwrz2gnsc0000gn/T/ipykernel_78517/1189923777.py:24: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"generated_at_utc\": datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === BUILD UI SNAPSHOTS (JSON) ===\n",
    "\n",
    "# factories.json: para mapa/lista\n",
    "factories_snapshot = []\n",
    "for _, r in df_fact2.iterrows():\n",
    "    factories_snapshot.append({\n",
    "        \"factory_id\": r[\"factory_id\"],\n",
    "        \"factory_name\": r[\"factory_name\"],\n",
    "        \"state\": r[\"state\"],\n",
    "        \"city\": r[\"city\"],\n",
    "        \"geo\": {\"lat\": float(r[\"lat\"]), \"lon\": float(r[\"lon\"])},\n",
    "        \"overall_risk_oos_7d\": float(r[\"overall_risk_oos_7d\"]) if not pd.isna(r[\"overall_risk_oos_7d\"]) else None,\n",
    "        \"severity\": r[\"severity\"],\n",
    "        \"critical_sku\": {\n",
    "            \"sku_id\": r[\"critical_sku_id\"],\n",
    "            \"sku_name\": r[\"critical_sku_name\"]\n",
    "        },\n",
    "        \"as_of_date\": AS_OF_DATE\n",
    "    })\n",
    "\n",
    "# predictions_latest.json: detalle por fábrica con top10\n",
    "predictions_snapshot = {\n",
    "    \"dataset_version\": \"mx_pilot_dummy_scoring_v1\",\n",
    "    \"generated_at_utc\": datetime.utcnow().strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "    \"as_of_date\": AS_OF_DATE,\n",
    "    \"horizon_days\": HORIZON_DAYS,\n",
    "    \"top_k\": TOP_K,\n",
    "    \"factories\": []\n",
    "}\n",
    "\n",
    "for fid, g in df_topk.groupby(\"factory_id\"):\n",
    "    g = g.sort_values(\"rank_in_factory_calc\")\n",
    "    fac_row = df_fact2[df_fact2[\"factory_id\"] == fid].iloc[0]\n",
    "\n",
    "    top10_list = []\n",
    "    for _, s in g.iterrows():\n",
    "        drivers_list = json.loads(s[\"drivers_calc_json\"]) if isinstance(s[\"drivers_calc_json\"], str) else []\n",
    "        top10_list.append({\n",
    "            \"rank\": int(s[\"rank_in_factory_calc\"]),\n",
    "            \"sku_id\": s[\"sku_id\"],\n",
    "            \"sku_name\": s[\"sku_name\"],\n",
    "            \"sku_family\": s.get(\"sku_family\", None),\n",
    "\n",
    "            \"risk_oos_7d\": float(s[\"risk_oos_7d_calc\"]) if not pd.isna(s[\"risk_oos_7d_calc\"]) else None,\n",
    "            \"confidence\": float(s[\"confidence_calc\"]) if not pd.isna(s[\"confidence_calc\"]) else None,\n",
    "\n",
    "            \"derived\": {\n",
    "                \"days_of_supply\": float(s[\"days_of_supply_calc\"]) if not pd.isna(s[\"days_of_supply_calc\"]) else None,\n",
    "                \"stockout_date_est\": s[\"stockout_date_est_calc\"],\n",
    "                \"stock_needed_next_7d\": float(s[\"stock_needed_next_7d_calc\"]) if not pd.isna(s[\"stock_needed_next_7d_calc\"]) else None\n",
    "            },\n",
    "            \"current_state\": {\n",
    "                \"on_hand_units\": float(s[\"on_hand_units\"]) if not pd.isna(s[\"on_hand_units\"]) else None,\n",
    "                \"in_transit_units\": float(s[\"in_transit_units\"]) if not pd.isna(s[\"in_transit_units\"]) else None,\n",
    "                \"on_order_units\": float(s[\"on_order_units\"]) if not pd.isna(s[\"on_order_units\"]) else None,\n",
    "                \"daily_demand_units\": float(s[\"daily_demand_units\"]) if not pd.isna(s[\"daily_demand_units\"]) else None,\n",
    "                \"lead_time_days_mean\": float(s[\"lead_time_days_mean\"]) if \"lead_time_days_mean\" in s and not pd.isna(s[\"lead_time_days_mean\"]) else None,\n",
    "                \"lead_time_days_std\": float(s[\"lead_time_days_std\"]) if not pd.isna(s[\"lead_time_days_std\"]) else None,\n",
    "                \"promo_uplift_index\": float(s[\"promo_uplift_index\"]) if not pd.isna(s[\"promo_uplift_index\"]) else None,\n",
    "                \"scrap_rate_7d\": float(s[\"scrap_rate_7d\"]) if not pd.isna(s[\"scrap_rate_7d\"]) else None\n",
    "            },\n",
    "            \"drivers\": drivers_list\n",
    "        })\n",
    "\n",
    "    predictions_snapshot[\"factories\"].append({\n",
    "        \"factory_id\": fid,\n",
    "        \"factory_name\": fac_row[\"factory_name\"],\n",
    "        \"state\": fac_row[\"state\"],\n",
    "        \"city\": fac_row[\"city\"],\n",
    "        \"geo\": {\"lat\": float(fac_row[\"lat\"]), \"lon\": float(fac_row[\"lon\"])},\n",
    "        \"overall_risk_oos_7d\": float(fac_row[\"overall_risk_oos_7d\"]) if not pd.isna(fac_row[\"overall_risk_oos_7d\"]) else None,\n",
    "        \"severity\": fac_row[\"severity\"],\n",
    "        \"critical_sku\": {\"sku_id\": fac_row[\"critical_sku_id\"], \"sku_name\": fac_row[\"critical_sku_name\"]},\n",
    "        \"top_10_skus\": top10_list\n",
    "    })\n",
    "\n",
    "len(factories_snapshot), len(predictions_snapshot[\"factories\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "719f7f2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('public/data/factories.json'),\n",
       " PosixPath('public/data/predictions_latest.json'))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === SAVE SNAPSHOTS ===\n",
    "factories_json_path = PUBLIC_DIR / \"factories.json\"\n",
    "preds_json_path = PUBLIC_DIR / \"predictions_latest.json\"\n",
    "\n",
    "with open(factories_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(factories_snapshot, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(preds_json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(predictions_snapshot, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "factories_json_path, preds_json_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0250d369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "factories.json factories: 3\n",
      "predictions_latest.json factories: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('Planta Irapuato', [(1, 'IRA-DAI-006', 0.6)])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === QUICK SANITY CHECKS ===\n",
    "print(\"factories.json factories:\", len(factories_snapshot))\n",
    "print(\"predictions_latest.json factories:\", len(predictions_snapshot[\"factories\"]))\n",
    "\n",
    "# ver top 3 skus de una fábrica\n",
    "example = predictions_snapshot[\"factories\"][0]\n",
    "example[\"factory_name\"], [(x[\"rank\"], x[\"sku_id\"], x[\"risk_oos_7d\"]) for x in example[\"top_10_skus\"][:3]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2226b32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('data/processed_scored/factories_scored.csv'),\n",
       " PosixPath('data/processed_scored/top10_skus_scored.csv'))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === OPTIONAL: también guardar CSV recalculados (para debug) ===\n",
    "OUT_DEBUG = Path(\"data/processed_scored\")\n",
    "OUT_DEBUG.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "df_fact2.to_csv(OUT_DEBUG / \"factories_scored.csv\", index=False)\n",
    "df_topk.to_csv(OUT_DEBUG / \"top10_skus_scored.csv\", index=False)\n",
    "\n",
    "OUT_DEBUG / \"factories_scored.csv\", OUT_DEBUG / \"top10_skus_scored.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ae8d9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listo. Snapshots generados en: /Users/davidbazalduamendez/Documents/GitHub/Danone_dummy/public/data\n"
     ]
    }
   ],
   "source": [
    "# === END ===\n",
    "# Ahora tu UI puede leer:\n",
    "# - /data/factories.json  (mapa + lista)\n",
    "# - /data/predictions_latest.json (detalle + top10)\n",
    "#\n",
    "# Siguiente: Notebook 03 (opcional) para preparar estructura de UI en React (Vite)\n",
    "# o para convertir esto a un endpoint si algún día lo quieren en backend.\n",
    "\n",
    "print(\"Listo. Snapshots generados en:\", PUBLIC_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7582c625",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_factories' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 12\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime, timezone\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# ==========\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# AJUSTA ESTO A TUS DATAFRAMES REALES\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# ==========\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# df_factories: columnas mínimas: plant_id, name, lat, lon\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# df_pred_latest: columnas mínimas: plant_id, sku_id, sku_name (si no, lo armamos), predicted_days_of_coverage (o algo equivalente)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m df_factories \u001b[38;5;241m=\u001b[39m \u001b[43mdf_factories\u001b[49m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     13\u001b[0m df_pred_latest \u001b[38;5;241m=\u001b[39m df_pred_latest\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     15\u001b[0m AS_OF_UTC \u001b[38;5;241m=\u001b[39m datetime\u001b[38;5;241m.\u001b[39mnow(timezone\u001b[38;5;241m.\u001b[39mutc)\u001b[38;5;241m.\u001b[39misoformat(timespec\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m+00:00\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mZ\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_factories' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# ==========\n",
    "# AJUSTA ESTO A TUS DATAFRAMES REALES\n",
    "# ==========\n",
    "# df_factories: columnas mínimas: plant_id, name, lat, lon\n",
    "# df_pred_latest: columnas mínimas: plant_id, sku_id, sku_name (si no, lo armamos), predicted_days_of_coverage (o algo equivalente)\n",
    "df_factories = df_factories.copy()\n",
    "df_pred_latest = df_pred_latest.copy()\n",
    "\n",
    "AS_OF_UTC = datetime.now(timezone.utc).isoformat(timespec=\"seconds\").replace(\"+00:00\",\"Z\")\n",
    "\n",
    "# ==========\n",
    "# Helpers\n",
    "# ==========\n",
    "def risk_band(score: float) -> str:\n",
    "    if score >= 90: return \"Critical\"\n",
    "    if score >= 70: return \"High\"\n",
    "    if score >= 40: return \"Medium\"\n",
    "    return \"Low\"\n",
    "\n",
    "def clamp(x, lo, hi):\n",
    "    return max(lo, min(hi, x))\n",
    "\n",
    "# Si no tienes sku_name, intenta armarlo por catálogo/merge antes.\n",
    "if \"sku_name\" not in df_pred_latest.columns:\n",
    "    df_pred_latest[\"sku_name\"] = df_pred_latest[\"sku_id\"].astype(str)\n",
    "\n",
    "# ==========\n",
    "# 1) Enriquecer prediction_latest\n",
    "# ==========\n",
    "# Si no tienes stockout_probability / risk_score, los derivamos desde predicted_days_of_coverage (demo)\n",
    "if \"predicted_days_of_coverage\" not in df_pred_latest.columns:\n",
    "    # si tú tienes \"days_of_coverage\" o \"coverage_days\", ajusta aquí:\n",
    "    if \"days_of_coverage\" in df_pred_latest.columns:\n",
    "        df_pred_latest[\"predicted_days_of_coverage\"] = df_pred_latest[\"days_of_coverage\"]\n",
    "    elif \"coverage_days\" in df_pred_latest.columns:\n",
    "        df_pred_latest[\"predicted_days_of_coverage\"] = df_pred_latest[\"coverage_days\"]\n",
    "    else:\n",
    "        # demo: inventar coverage si no existe (no ideal, pero evita romper)\n",
    "        df_pred_latest[\"predicted_days_of_coverage\"] = np.random.uniform(2.0, 7.0, size=len(df_pred_latest)).round(2)\n",
    "\n",
    "# stockout_probability: alta si cobertura baja\n",
    "if \"stockout_probability\" not in df_pred_latest.columns:\n",
    "    doc = df_pred_latest[\"predicted_days_of_coverage\"].astype(float)\n",
    "    df_pred_latest[\"stockout_probability\"] = (1 - (doc / 6)).clip(0.05, 0.95).round(2)\n",
    "\n",
    "# risk_score: mezcla prob + cobertura invertida\n",
    "if \"risk_score\" not in df_pred_latest.columns:\n",
    "    doc = df_pred_latest[\"predicted_days_of_coverage\"].astype(float)\n",
    "    prob = df_pred_latest[\"stockout_probability\"].astype(float)\n",
    "    score = 100 * (0.65 * prob + 0.35 * ((6 - doc) / 6).clip(0,1))\n",
    "    df_pred_latest[\"risk_score\"] = score.round().astype(int)\n",
    "\n",
    "df_pred_latest[\"risk_band\"] = df_pred_latest[\"risk_score\"].apply(risk_band)\n",
    "\n",
    "# t+1 y t+7 (si no existen, generamos demo proporcional)\n",
    "if \"predicted_closing_stock_units_t1\" not in df_pred_latest.columns:\n",
    "    df_pred_latest[\"predicted_closing_stock_units_t1\"] = (np.random.uniform(2000, 50000, size=len(df_pred_latest))).round().astype(int)\n",
    "\n",
    "if \"predicted_closing_stock_units_t7\" not in df_pred_latest.columns:\n",
    "    df_pred_latest[\"predicted_closing_stock_units_t7\"] = (df_pred_latest[\"predicted_closing_stock_units_t1\"] * np.random.uniform(0.2, 0.9, size=len(df_pred_latest))).round().astype(int)\n",
    "\n",
    "# expected_stockout_date (si prob alta y cobertura baja)\n",
    "if \"expected_stockout_date\" not in df_pred_latest.columns:\n",
    "    # demo: si cobertura < 3.0 -> stockout en 2-4 días\n",
    "    days = np.where(df_pred_latest[\"predicted_days_of_coverage\"] < 3.0,\n",
    "                    np.random.randint(2,5,size=len(df_pred_latest)),\n",
    "                    np.random.randint(5,10,size=len(df_pred_latest)))\n",
    "    base = pd.Timestamp(AS_OF_UTC)\n",
    "    df_pred_latest[\"expected_stockout_date\"] = [(base + pd.Timedelta(days=int(d))).date().isoformat() for d in days]\n",
    "\n",
    "# drivers (si no tienes, genera 3 drivers fijos con pesos que sumen 1)\n",
    "def make_drivers(row):\n",
    "    # pesos demo pero creíbles\n",
    "    w1 = clamp(0.35 + (3.5 - float(row[\"predicted_days_of_coverage\"])) * 0.08, 0.25, 0.65)\n",
    "    w2 = clamp(0.25 + float(row[\"stockout_probability\"]) * 0.15, 0.15, 0.45)\n",
    "    w3 = max(0.05, 1 - w1 - w2)\n",
    "    # normaliza\n",
    "    s = w1 + w2 + w3\n",
    "    w1, w2, w3 = w1/s, w2/s, w3/s\n",
    "    return [\n",
    "        {\"driver\": \"Low Days of Coverage\", \"weight\": round(w1, 2)},\n",
    "        {\"driver\": \"Demand Spike\", \"weight\": round(w2, 2)},\n",
    "        {\"driver\": \"Lead Time Variability\", \"weight\": round(w3, 2)}\n",
    "    ]\n",
    "\n",
    "if \"drivers\" not in df_pred_latest.columns:\n",
    "    df_pred_latest[\"drivers\"] = df_pred_latest.apply(make_drivers, axis=1)\n",
    "\n",
    "# recommended_actions (simple rules)\n",
    "def make_actions(row):\n",
    "    actions = []\n",
    "    if row[\"risk_band\"] in [\"Critical\",\"High\"]:\n",
    "        actions.append(\"Reallocate from lower-risk plant within 48–72h\")\n",
    "        actions.append(\"Expedite production / prioritise next slot\")\n",
    "    if float(row[\"predicted_days_of_coverage\"]) < 3.5:\n",
    "        actions.append(\"Increase replenishment frequency for next 7 days\")\n",
    "    # evita demasiadas\n",
    "    return actions[:3]\n",
    "\n",
    "if \"recommended_actions\" not in df_pred_latest.columns:\n",
    "    df_pred_latest[\"recommended_actions\"] = df_pred_latest.apply(make_actions, axis=1)\n",
    "\n",
    "# ==========\n",
    "# 2) Enriquecer factories agregando agregados desde predictions\n",
    "# ==========\n",
    "agg = (df_pred_latest\n",
    "       .groupby(\"plant_id\")\n",
    "       .agg(\n",
    "           global_risk_score=(\"risk_score\",\"max\"),\n",
    "           skus_at_risk_count=(\"risk_score\", lambda s: int((s>=40).sum())),\n",
    "           critical_skus_count=(\"risk_score\", lambda s: int((s>=90).sum())),\n",
    "           avg_stockout_probability=(\"stockout_probability\",\"mean\")\n",
    "       )\n",
    "       .reset_index())\n",
    "\n",
    "# next_stockout_date por planta: el mínimo entre SKUs con riesgo alto\n",
    "tmp = df_pred_latest.copy()\n",
    "tmp[\"expected_stockout_date\"] = pd.to_datetime(tmp[\"expected_stockout_date\"], errors=\"coerce\")\n",
    "next_so = (tmp[tmp[\"risk_score\"]>=70]\n",
    "           .groupby(\"plant_id\")[\"expected_stockout_date\"]\n",
    "           .min()\n",
    "           .reset_index()\n",
    "           .rename(columns={\"expected_stockout_date\":\"next_stockout_date\"}))\n",
    "next_so[\"next_stockout_date\"] = next_so[\"next_stockout_date\"].dt.date.astype(str)\n",
    "\n",
    "# top_skus (top 5)\n",
    "top_skus = []\n",
    "for pid, g in df_pred_latest.groupby(\"plant_id\"):\n",
    "    top = (g.sort_values([\"risk_score\",\"stockout_probability\"], ascending=False)\n",
    "            .head(5)[[\"sku_id\",\"sku_name\",\"risk_score\",\"risk_band\"]])\n",
    "    top_skus.append({\"plant_id\": pid, \"top_skus\": top.to_dict(orient=\"records\")})\n",
    "top_skus_df = pd.DataFrame(top_skus)\n",
    "\n",
    "df_factories = df_factories.merge(agg, on=\"plant_id\", how=\"left\")\n",
    "df_factories = df_factories.merge(next_so, on=\"plant_id\", how=\"left\")\n",
    "df_factories = df_factories.merge(top_skus_df, on=\"plant_id\", how=\"left\")\n",
    "\n",
    "df_factories[\"global_risk_score\"] = df_factories[\"global_risk_score\"].fillna(0).astype(int)\n",
    "df_factories[\"risk_band\"] = df_factories[\"global_risk_score\"].apply(risk_band)\n",
    "\n",
    "# revenue/volume demo (si no tienes: derivado del #SKUs en riesgo)\n",
    "if \"estimated_revenue_at_risk_mxn\" not in df_factories.columns:\n",
    "    df_factories[\"estimated_revenue_at_risk_mxn\"] = (df_factories[\"skus_at_risk_count\"].fillna(0) * np.random.uniform(250000, 900000, size=len(df_factories))).round().astype(int)\n",
    "\n",
    "if \"estimated_volume_at_risk_units\" not in df_factories.columns:\n",
    "    df_factories[\"estimated_volume_at_risk_units\"] = (df_factories[\"skus_at_risk_count\"].fillna(0) * np.random.uniform(15000, 90000, size=len(df_factories))).round().astype(int)\n",
    "\n",
    "# trend + drivers (demo)\n",
    "def make_trend(score):\n",
    "    # sparkline que termina en score\n",
    "    start = clamp(score - np.random.randint(-6, 14), 0, 100)\n",
    "    vals = np.linspace(start, score, 7) + np.random.normal(0, 1.2, 7)\n",
    "    vals = np.clip(vals, 0, 100).round().astype(int).tolist()\n",
    "    vs = int(vals[-1] - vals[0])\n",
    "    direction = \"up\" if vs > 0 else (\"down\" if vs < 0 else \"flat\")\n",
    "    return {\"vs_prev_7d_pp\": vs, \"direction\": direction, \"sparkline_7d\": vals}\n",
    "\n",
    "def make_drivers_plant(score):\n",
    "    # distribuciones distintas por severidad\n",
    "    if score >= 90:\n",
    "        return [\n",
    "            {\"driver\":\"Low Days of Coverage\",\"contribution_pct\":45},\n",
    "            {\"driver\":\"Demand Spike\",\"contribution_pct\":25},\n",
    "            {\"driver\":\"Lead Time Variability\",\"contribution_pct\":20},\n",
    "            {\"driver\":\"Fill Rate Drop\",\"contribution_pct\":10}\n",
    "        ]\n",
    "    if score >= 70:\n",
    "        return [\n",
    "            {\"driver\":\"Demand Volatility\",\"contribution_pct\":34},\n",
    "            {\"driver\":\"Low Days of Coverage\",\"contribution_pct\":28},\n",
    "            {\"driver\":\"Lead Time Variability\",\"contribution_pct\":22},\n",
    "            {\"driver\":\"Distribution Constraints\",\"contribution_pct\":16}\n",
    "        ]\n",
    "    return [\n",
    "        {\"driver\":\"Lead Time Variability\",\"contribution_pct\":35},\n",
    "        {\"driver\":\"Capacity Constraints\",\"contribution_pct\":25},\n",
    "        {\"driver\":\"Low Days of Coverage\",\"contribution_pct\":22},\n",
    "        {\"driver\":\"Demand Volatility\",\"contribution_pct\":18}\n",
    "    ]\n",
    "\n",
    "df_factories[\"trend\"] = df_factories[\"global_risk_score\"].apply(make_trend)\n",
    "df_factories[\"drivers\"] = df_factories[\"global_risk_score\"].apply(make_drivers_plant)\n",
    "\n",
    "# ==========\n",
    "# 3) Export a Vite public/data\n",
    "# ==========\n",
    "# Ajusta esta ruta a tu repo real. Esta asume que tu notebook está en una carpeta hermana a ui-dashboard.\n",
    "OUT = Path(\"../ui-dashboard/public/data\")\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# factories.json\n",
    "factories_out = []\n",
    "for _, r in df_factories.iterrows():\n",
    "    factories_out.append({\n",
    "        \"plant_id\": r[\"plant_id\"],\n",
    "        \"name\": r[\"name\"],\n",
    "        \"location\": {\"lat\": float(r[\"lat\"]), \"lon\": float(r[\"lon\"])},\n",
    "        \"global_risk_score\": int(r[\"global_risk_score\"]),\n",
    "        \"risk_band\": r[\"risk_band\"],\n",
    "        \"skus_at_risk_count\": int(r.get(\"skus_at_risk_count\", 0) or 0),\n",
    "        \"critical_skus_count\": int(r.get(\"critical_skus_count\", 0) or 0),\n",
    "        \"next_stockout_date\": r.get(\"next_stockout_date\", None),\n",
    "        \"estimated_revenue_at_risk_mxn\": int(r[\"estimated_revenue_at_risk_mxn\"]),\n",
    "        \"estimated_volume_at_risk_units\": int(r[\"estimated_volume_at_risk_units\"]),\n",
    "        \"trend\": r[\"trend\"],\n",
    "        \"drivers\": r[\"drivers\"],\n",
    "        \"top_skus\": r[\"top_skus\"] if isinstance(r[\"top_skus\"], list) else []\n",
    "    })\n",
    "\n",
    "with open(OUT/\"factories.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(factories_out, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# prediction_latest.json\n",
    "pred_out = {\n",
    "    \"as_of_utc\": AS_OF_UTC,\n",
    "    \"horizon_days\": 7,\n",
    "    \"rows\": []\n",
    "}\n",
    "\n",
    "cols_needed = [\n",
    "    \"plant_id\",\"sku_id\",\"sku_name\",\n",
    "    \"risk_score\",\"risk_band\",\n",
    "    \"predicted_days_of_coverage\",\n",
    "    \"expected_stockout_date\",\n",
    "    \"stockout_probability\",\n",
    "    \"predicted_closing_stock_units_t1\",\n",
    "    \"predicted_closing_stock_units_t7\",\n",
    "    \"drivers\",\"recommended_actions\"\n",
    "]\n",
    "\n",
    "for _, r in df_pred_latest[cols_needed].iterrows():\n",
    "    pred_out[\"rows\"].append({\n",
    "        \"plant_id\": r[\"plant_id\"],\n",
    "        \"sku_id\": r[\"sku_id\"],\n",
    "        \"sku_name\": r[\"sku_name\"],\n",
    "        \"risk_score\": int(r[\"risk_score\"]),\n",
    "        \"risk_band\": r[\"risk_band\"],\n",
    "        \"predicted_days_of_coverage\": float(r[\"predicted_days_of_coverage\"]),\n",
    "        \"expected_stockout_date\": r[\"expected_stockout_date\"],\n",
    "        \"stockout_probability\": float(r[\"stockout_probability\"]),\n",
    "        \"predicted_closing_stock_units_t1\": int(r[\"predicted_closing_stock_units_t1\"]),\n",
    "        \"predicted_closing_stock_units_t7\": int(r[\"predicted_closing_stock_units_t7\"]),\n",
    "        \"drivers\": r[\"drivers\"],\n",
    "        \"recommended_actions\": r[\"recommended_actions\"]\n",
    "    })\n",
    "\n",
    "with open(OUT/\"prediction_latest.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(pred_out, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"Wrote:\", OUT/\"factories.json\", \"and\", OUT/\"prediction_latest.json\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
