{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "decd58aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: demo_payload.json, sales_history_demo.csv, inventory_history_demo.csv, forecast_output_demo.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# -----------------------------\n",
    "# 0) CONFIG\n",
    "# -----------------------------\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "AS_OF = pd.Timestamp(\"2026-01-15\", tz=\"UTC\")\n",
    "HISTORY_DAYS = 180\n",
    "HORIZON_DAYS = 7\n",
    "\n",
    "plants = [\n",
    "    {\"plant_id\": \"MX-TOL\", \"name\": \"Toluca Plant\", \"lat\": 19.2826, \"lon\": -99.6557},\n",
    "    {\"plant_id\": \"MX-IRA\", \"name\": \"Irapuato Plant\", \"lat\": 20.6767, \"lon\": -101.3469},\n",
    "    {\"plant_id\": \"MX-VMX\", \"name\": \"Valley of Mexico Plant\", \"lat\": 19.4326, \"lon\": -99.1332},\n",
    "    {\"plant_id\": \"MX-GDL\", \"name\": \"Guadalajara Plant\", \"lat\": 20.6597, \"lon\": -103.3496},\n",
    "    {\"plant_id\": \"MX-SLP\", \"name\": \"San Luis Potosi Plant\", \"lat\": 22.1565, \"lon\": -100.9855},\n",
    "]\n",
    "\n",
    "# Tus productos reales (los que listaste)\n",
    "sku_names = [\n",
    "    \"Danone Bebible Natural Deslactosado\",\n",
    "    \"Danone Bebible de Fresa Deslactosado\",\n",
    "    \"Danone Bebible de Frutos Verdes Deslactosado\",\n",
    "    \"Danone Bebible de Mango y Durazno Deslactosado\",\n",
    "    \"Danone Natural Familiar sin azúcar\",\n",
    "    \"Danone Natural con fermentos\",\n",
    "    \"Danone Natural con miel\",\n",
    "    \"Danone Familiar con trozos de durazno\",\n",
    "    \"Danone Familiar con trozos de fresa y moras\",\n",
    "    \"Danone Familiar con trozos de manzana\",\n",
    "    \"Danone Familiar con trozos de piña y coco\",\n",
    "    \"Danone Familiar con trozos de mango\",\n",
    "    \"Danone Familiar miel y granola\",\n",
    "    \"Danone Familiar coco y nuez con cereal\",\n",
    "    \"Danone Familiar sabor durazno (sin trozos)\",\n",
    "    \"Danone Familiar sabor manzana (sin trozos)\",\n",
    "    \"Danone Familiar sabor fresa (sin trozos)\",\n",
    "    \"Danone Griego sin azúcar\",\n",
    "    \"Danone Griego endulzado\",\n",
    "    \"Yoghurt con cereal de fresa con chocoarroz\",\n",
    "    \"Yoghurt con cereal de vainilla con hojuelas de maíz\",\n",
    "    \"Yoghurt con cereal de fresa con azucaradas\",\n",
    "    \"Yoghurt con cereal de manzana con frutiaros\",\n",
    "    \"Licuado de fresa y plátano con cereales\",\n",
    "    \"Licuado de nuez con cereales\",\n",
    "]\n",
    "\n",
    "# Construimos IDs simples estables\n",
    "def slug(s):\n",
    "    return (\n",
    "        s.lower()\n",
    "         .replace(\" \", \"-\")\n",
    "         .replace(\"á\",\"a\").replace(\"é\",\"e\").replace(\"í\",\"i\").replace(\"ó\",\"o\").replace(\"ú\",\"u\")\n",
    "         .replace(\"ñ\",\"n\").replace(\"(\",\"\").replace(\")\",\"\")\n",
    "         .replace(\"/\",\"-\")\n",
    "         .replace(\",\",\"\")\n",
    "    )\n",
    "\n",
    "sku_catalog = []\n",
    "for name in sku_names:\n",
    "    sku_catalog.append({\n",
    "        \"sku_id\": f\"SKU-{slug(name)[:40]}\",\n",
    "        \"display_name\": name,\n",
    "        \"brand\": \"Danone\"\n",
    "    })\n",
    "\n",
    "# -----------------------------\n",
    "# 1) GENERATE SALES HISTORY\n",
    "# -----------------------------\n",
    "dates = pd.date_range(end=AS_OF, periods=HISTORY_DAYS, freq=\"D\", tz=\"UTC\")\n",
    "\n",
    "rows = []\n",
    "for p in plants:\n",
    "    plant_multiplier = np.random.uniform(0.7, 1.3)  # tamaño de la planta\n",
    "    for sku in sku_catalog:\n",
    "        base = np.random.uniform(800, 12000) * plant_multiplier\n",
    "\n",
    "        # Semana: patrón por día\n",
    "        dow = np.array([d.dayofweek for d in dates])  # 0=Mon\n",
    "        weekly = 1 + 0.10 * np.sin(2*np.pi * dow/7)\n",
    "\n",
    "        # Tendencia suave\n",
    "        t = np.arange(len(dates))\n",
    "        trend = 1 + np.random.uniform(-0.0008, 0.0012) * t\n",
    "\n",
    "        # Promo: 10% de días con uplift\n",
    "        promo_flag = (np.random.rand(len(dates)) < 0.10).astype(int)\n",
    "        promo_uplift = 1 + promo_flag * np.random.uniform(0.10, 0.35)\n",
    "\n",
    "        noise = np.random.normal(1.0, 0.08, size=len(dates))  # variabilidad\n",
    "\n",
    "        sales = np.maximum(0, base * weekly * trend * promo_uplift * noise).round().astype(int)\n",
    "\n",
    "        # Precio demo\n",
    "        price = np.random.uniform(8, 45)  # MXN por unidad (demo)\n",
    "        net_sales = (sales * price).round(2)\n",
    "\n",
    "        for i, d in enumerate(dates):\n",
    "            rows.append({\n",
    "                \"date\": d.date().isoformat(),\n",
    "                \"plant_id\": p[\"plant_id\"],\n",
    "                \"sku_id\": sku[\"sku_id\"],\n",
    "                \"sales_units\": int(sales[i]),\n",
    "                \"net_sales_mxn\": float(net_sales[i]),\n",
    "                \"promo_flag\": int(promo_flag[i]),\n",
    "                \"price_mxn\": float(round(price, 2))\n",
    "            })\n",
    "\n",
    "sales_history = pd.DataFrame(rows)\n",
    "\n",
    "# -----------------------------\n",
    "# 2) GENERATE INVENTORY HISTORY (simple stock flow)\n",
    "# closing = opening + production + inbound - outbound - sales - scrap\n",
    "# -----------------------------\n",
    "inv_rows = []\n",
    "for (plant_id, sku_id), grp in sales_history.groupby([\"plant_id\", \"sku_id\"]):\n",
    "    grp = grp.sort_values(\"date\").reset_index(drop=True)\n",
    "\n",
    "    # Start stock ~ 10-20 days of average sales\n",
    "    avg_sales = grp[\"sales_units\"].mean()\n",
    "    opening = int(avg_sales * np.random.uniform(10, 20))\n",
    "\n",
    "    for _, r in grp.iterrows():\n",
    "        sales = int(r[\"sales_units\"])\n",
    "        # production intenta cubrir un % de ventas, pero con variación\n",
    "        production = int(max(0, sales * np.random.uniform(0.7, 1.15)))\n",
    "        inbound = int(max(0, avg_sales * np.random.uniform(0.0, 0.25)))\n",
    "        outbound = int(max(0, avg_sales * np.random.uniform(0.0, 0.15)))\n",
    "        scrap = int(max(0, sales * np.random.uniform(0.0, 0.01)))\n",
    "\n",
    "        closing = opening + production + inbound - outbound - sales - scrap\n",
    "        stockout_flag = 1 if closing <= 0 else 0\n",
    "        closing = max(0, closing)\n",
    "\n",
    "        inv_rows.append({\n",
    "            \"date\": r[\"date\"],\n",
    "            \"plant_id\": plant_id,\n",
    "            \"sku_id\": sku_id,\n",
    "            \"opening_stock_units\": opening,\n",
    "            \"production_units\": production,\n",
    "            \"inbound_transfers_units\": inbound,\n",
    "            \"outbound_transfers_units\": outbound,\n",
    "            \"sales_units\": sales,\n",
    "            \"scrap_units\": scrap,\n",
    "            \"closing_stock_units\": closing,\n",
    "            \"stockout_flag\": stockout_flag\n",
    "        })\n",
    "\n",
    "        opening = closing\n",
    "\n",
    "inventory_history = pd.DataFrame(inv_rows)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) FORECAST (baseline: moving average 14d) + STOCK PROJECTION\n",
    "# -----------------------------\n",
    "def moving_avg_forecast(series, window=14, horizon=7):\n",
    "    last = series.iloc[-window:].mean()\n",
    "    return np.repeat(last, horizon)\n",
    "\n",
    "forecast_rows = []\n",
    "future_dates = pd.date_range(start=AS_OF + pd.Timedelta(days=1), periods=HORIZON_DAYS, freq=\"D\", tz=\"UTC\")\n",
    "\n",
    "for (plant_id, sku_id), sales_grp in sales_history.groupby([\"plant_id\", \"sku_id\"]):\n",
    "    sales_grp = sales_grp.sort_values(\"date\")\n",
    "    inv_grp = inventory_history[(inventory_history.plant_id==plant_id) & (inventory_history.sku_id==sku_id)].sort_values(\"date\")\n",
    "\n",
    "    hist_sales = sales_grp[\"sales_units\"]\n",
    "    fc = moving_avg_forecast(hist_sales, window=14, horizon=HORIZON_DAYS)\n",
    "\n",
    "    # stock projection using last closing + assume planned production covers 90% of forecast\n",
    "    last_stock = int(inv_grp[\"closing_stock_units\"].iloc[-1])\n",
    "    proj_stock = last_stock\n",
    "\n",
    "    for i, d in enumerate(future_dates):\n",
    "        forecast_sales = int(round(fc[i]))\n",
    "        planned_prod = int(round(forecast_sales * 0.90))\n",
    "        # simplistic: no transfers\n",
    "        proj_stock = max(0, proj_stock + planned_prod - forecast_sales)\n",
    "\n",
    "        # days of coverage = current projected stock / forecast daily sales\n",
    "        doc = float(proj_stock / max(1, forecast_sales))\n",
    "        stockout_prob = float(min(0.95, max(0.05, 1 - (doc/5))))  # demo: <5 days -> higher prob\n",
    "\n",
    "        forecast_rows.append({\n",
    "            \"date\": d.date().isoformat(),\n",
    "            \"plant_id\": plant_id,\n",
    "            \"sku_id\": sku_id,\n",
    "            \"model_id\": \"baseline_moving_avg_14d\",\n",
    "            \"forecast_sales_units\": forecast_sales,\n",
    "            \"predicted_closing_stock_units\": int(proj_stock),\n",
    "            \"predicted_days_of_coverage\": round(doc, 2),\n",
    "            \"stockout_probability\": round(stockout_prob, 2)\n",
    "        })\n",
    "\n",
    "forecast_output = pd.DataFrame(forecast_rows)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) LIVE RISK SCORING (today snapshot)\n",
    "# -----------------------------\n",
    "# Use min predicted DoC in horizon and stockout_probability peak to define risk\n",
    "live_rows = []\n",
    "for (plant_id, sku_id), fgrp in forecast_output.groupby([\"plant_id\",\"sku_id\"]):\n",
    "    min_doc = fgrp[\"predicted_days_of_coverage\"].min()\n",
    "    max_prob = fgrp[\"stockout_probability\"].max()\n",
    "\n",
    "    # Risk score demo: weighted prob + inverse coverage\n",
    "    risk = 100 * (0.65 * max_prob + 0.35 * min(1.0, (5 - min_doc)/5))\n",
    "    risk = int(round(np.clip(risk, 0, 100)))\n",
    "\n",
    "    next_stockout = None\n",
    "    # first day where predicted stock hits 0\n",
    "    zeros = fgrp[fgrp[\"predicted_closing_stock_units\"] == 0]\n",
    "    if len(zeros) > 0:\n",
    "        next_stockout = zeros.iloc[0][\"date\"]\n",
    "\n",
    "    live_rows.append({\n",
    "        \"plant_id\": plant_id,\n",
    "        \"sku_id\": sku_id,\n",
    "        \"risk_score\": risk,\n",
    "        \"min_predicted_days_of_coverage\": float(min_doc),\n",
    "        \"max_stockout_probability\": float(max_prob),\n",
    "        \"next_stockout_date\": next_stockout\n",
    "    })\n",
    "\n",
    "live_sku_risk = pd.DataFrame(live_rows)\n",
    "\n",
    "def band(score):\n",
    "    if score >= 90: return \"Critical\"\n",
    "    if score >= 70: return \"High\"\n",
    "    if score >= 40: return \"Medium\"\n",
    "    return \"Low\"\n",
    "\n",
    "live_sku_risk[\"risk_band\"] = live_sku_risk[\"risk_score\"].apply(band)\n",
    "\n",
    "# Plant-level aggregation\n",
    "plant_summary = (live_sku_risk\n",
    "                 .groupby(\"plant_id\")\n",
    "                 .agg(global_risk_score=(\"risk_score\",\"max\"),\n",
    "                      skus_at_risk=(\"risk_score\", lambda s: int((s>=40).sum())),\n",
    "                      critical_skus=(\"risk_score\", lambda s: int((s>=90).sum())))\n",
    "                 .reset_index())\n",
    "\n",
    "# -----------------------------\n",
    "# 5) BUILD JSON PAYLOAD\n",
    "# -----------------------------\n",
    "sku_lookup = {s[\"sku_id\"]: s for s in sku_catalog}\n",
    "plant_lookup = {p[\"plant_id\"]: p for p in plants}\n",
    "\n",
    "plants_payload = []\n",
    "for _, pr in plant_summary.iterrows():\n",
    "    pid = pr[\"plant_id\"]\n",
    "    pinfo = plant_lookup[pid]\n",
    "    plant_risk = int(pr[\"global_risk_score\"])\n",
    "    plant_band = band(plant_risk)\n",
    "\n",
    "    # Top 10 SKUs by risk for this plant\n",
    "    top = (live_sku_risk[live_sku_risk.plant_id==pid]\n",
    "           .sort_values([\"risk_score\",\"max_stockout_probability\"], ascending=False)\n",
    "           .head(10))\n",
    "\n",
    "    top_risks = []\n",
    "    for rank, (_, r) in enumerate(top.iterrows(), start=1):\n",
    "        top_risks.append({\n",
    "            \"rank\": rank,\n",
    "            \"sku_id\": r[\"sku_id\"],\n",
    "            \"sku_name\": sku_lookup[r[\"sku_id\"]][\"display_name\"],\n",
    "            \"risk_score\": int(r[\"risk_score\"]),\n",
    "            \"risk_band\": r[\"risk_band\"],\n",
    "            \"predicted_min_days_of_coverage\": round(float(r[\"min_predicted_days_of_coverage\"]), 2),\n",
    "            \"max_stockout_probability\": round(float(r[\"max_stockout_probability\"]), 2),\n",
    "            \"expected_stockout_date\": r[\"next_stockout_date\"]\n",
    "        })\n",
    "\n",
    "    plants_payload.append({\n",
    "        \"plant_id\": pid,\n",
    "        \"name\": pinfo[\"name\"],\n",
    "        \"location\": {\"lat\": pinfo[\"lat\"], \"lon\": pinfo[\"lon\"]},\n",
    "        \"global_risk_score\": plant_risk,\n",
    "        \"risk_band\": plant_band,\n",
    "        \"skus_at_risk_count\": int(pr[\"skus_at_risk\"]),\n",
    "        \"critical_skus_count\": int(pr[\"critical_skus\"]),\n",
    "        \"top_risks\": top_risks\n",
    "    })\n",
    "\n",
    "payload = {\n",
    "    \"meta\": {\n",
    "        \"product\": \"Risk Intelligence\",\n",
    "        \"pilot\": \"MX Pilot\",\n",
    "        \"language\": \"en\",\n",
    "        \"horizon_days\": HORIZON_DAYS,\n",
    "        \"as_of_utc\": AS_OF.isoformat(),\n",
    "        \"currency\": \"MXN\",\n",
    "        \"seed\": SEED\n",
    "    },\n",
    "    \"tabs\": [\n",
    "        {\"id\": \"live_risk\", \"label\": \"Live Risk\"},\n",
    "        {\"id\": \"historical_forecast\", \"label\": \"Historical & Forecast\"}\n",
    "    ],\n",
    "    \"catalog\": {\n",
    "        \"skus\": sku_catalog,\n",
    "        \"plants\": [{\"plant_id\": p[\"plant_id\"], \"name\": p[\"name\"]} for p in plants]\n",
    "    },\n",
    "    \"live_risk\": {\n",
    "        \"plants\": plants_payload\n",
    "    },\n",
    "    \"historical_forecast\": {\n",
    "        \"granularity\": \"daily\",\n",
    "        \"default_history_days\": HISTORY_DAYS,\n",
    "        \"datasets\": {\n",
    "            \"sales_history\": sales_history.to_dict(orient=\"records\"),\n",
    "            \"inventory_history\": inventory_history.to_dict(orient=\"records\"),\n",
    "            \"forecast_output\": forecast_output.to_dict(orient=\"records\")\n",
    "        },\n",
    "        \"models\": [\n",
    "            {\"model_id\":\"baseline_moving_avg_14d\", \"type\":\"baseline\", \"description\":\"14-day moving average sales forecast + stock projection\"}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(\"demo_payload.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "sales_history.to_csv(\"sales_history_demo.csv\", index=False)\n",
    "inventory_history.to_csv(\"inventory_history_demo.csv\", index=False)\n",
    "forecast_output.to_csv(\"forecast_output_demo.csv\", index=False)\n",
    "\n",
    "print(\"Saved: demo_payload.json, sales_history_demo.csv, inventory_history_demo.csv, forecast_output_demo.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
